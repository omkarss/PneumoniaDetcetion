{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import cv2                 \n",
    "import numpy as np         \n",
    "import os                  \n",
    "from random import shuffle\n",
    "from tqdm import tqdm  \n",
    "import scipy\n",
    "import skimage\n",
    "from skimage.transform import resize\n",
    "#print(os.listdir(\"chest_xray\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_DIR = \"train/\"\n",
    "TEST_DIR =  \"test/\"\n",
    "VAL_DIR = \"val/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_label(Dir):\n",
    "    for nextdir in os.listdir(Dir):\n",
    "        if not nextdir.startswith('.'):\n",
    "            if nextdir in ['NORMAL']:\n",
    "                label = 0\n",
    "            elif nextdir in ['PNEUMONIA']:\n",
    "                label = 1\n",
    "            else:\n",
    "                label = 2\n",
    "    return nextdir, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing_data(Dir):\n",
    "    X = []\n",
    "    y = []\n",
    "    \n",
    "    for nextdir in os.listdir(Dir):\n",
    "        nextdir, label = get_label(Dir)\n",
    "        temp = Dir + nextdir\n",
    "        \n",
    "        for image_filename in tqdm(os.listdir(temp)):\n",
    "            path = os.path.join(temp + '/' , image_filename)\n",
    "            img = cv2.imread(path,cv2.IMREAD_GRAYSCALE)\n",
    "            if img is not None:\n",
    "                img = skimage.transform.resize(img, (150, 150, 3))\n",
    "                img = np.asarray(img)\n",
    "                X.append(img)\n",
    "                y.append(label)\n",
    "            \n",
    "    X = np.asarray(X)\n",
    "    y = np.asarray(y)\n",
    "    \n",
    "    return X,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(Dir):\n",
    "    X = []\n",
    "    y = []\n",
    "    for nextDir in os.listdir(Dir):\n",
    "        if not nextDir.startswith('.'):\n",
    "            if nextDir in ['NORMAL']:\n",
    "                label = 0\n",
    "            elif nextDir in ['PNEUMONIA']:\n",
    "                label = 1\n",
    "            else:\n",
    "                label = 2\n",
    "                \n",
    "            temp = Dir + nextDir\n",
    "                \n",
    "            for file in tqdm(os.listdir(temp)):\n",
    "                img = cv2.imread(temp + '/' + file)\n",
    "                if img is not None:\n",
    "                    img = skimage.transform.resize(img, (150, 150, 3))\n",
    "                    #img_file = scipy.misc.imresize(arr=img_file, size=(150, 150, 3))\n",
    "                    img = np.asarray(img)\n",
    "                    X.append(img)\n",
    "                    y.append(label)\n",
    "                    \n",
    "    X = np.asarray(X)\n",
    "    y = np.asarray(y)\n",
    "    return X,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/3877 [00:00<?, ?it/s]/Users/omkar/anaconda3/lib/python3.7/site-packages/skimage/transform/_warps.py:105: UserWarning: The default mode, 'constant', will be changed to 'reflect' in skimage 0.15.\n",
      "  warn(\"The default mode, 'constant', will be changed to 'reflect' in \"\n",
      "/Users/omkar/anaconda3/lib/python3.7/site-packages/skimage/transform/_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "100%|██████████| 3877/3877 [02:59<00:00, 14.98it/s]\n",
      "100%|██████████| 1343/1343 [02:36<00:00,  8.15it/s]\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train = get_data(TRAIN_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 390/390 [00:19<00:00, 20.32it/s]\n",
      "100%|██████████| 234/234 [00:23<00:00, 10.04it/s]\n"
     ]
    }
   ],
   "source": [
    "X_test , y_test = get_data(TEST_DIR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5216, 150, 150, 3) \n",
      " (624, 150, 150, 3)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape,'\\n',X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5216,) \n",
      " (624,)\n"
     ]
    }
   ],
   "source": [
    "print(y_train.shape,'\\n',y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from keras.utils.np_utils import to_categorical\n",
    "\n",
    "y_train = to_categorical(y_train, 2)\n",
    "y_test = to_categorical(y_test, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5216, 2) \n",
      " (624, 2)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(y_train.shape,'\\n',y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "Pimages = os.listdir(TRAIN_DIR + \"PNEUMONIA\")\n",
    "Nimages = os.listdir(TRAIN_DIR + \"NORMAL\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/omkar/anaconda3/lib/python3.7/site-packages/keras/callbacks.py:1065: UserWarning: `epsilon` argument is deprecated and will be removed, use `min_delta` instead.\n",
      "  warnings.warn('`epsilon` argument is deprecated and '\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from keras.callbacks import ReduceLROnPlateau , ModelCheckpoint\n",
    "lr_reduce = ReduceLROnPlateau(monitor='val_acc', factor=0.1, epsilon=0.0001, patience=1, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath=\"weights.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense , Activation\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Flatten\n",
    "from keras.constraints import maxnorm\n",
    "from keras.optimizers import SGD , RMSprop\n",
    "from keras.layers import Conv2D , BatchNormalization\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.utils import np_utils\n",
    "from keras import backend as K\n",
    "K.set_image_dim_ordering('th')\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from keras.wrappers.scikit_learn import KerasClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=X_train.reshape(5216,3,150,150)\n",
    "X_test=X_test.reshape(624,3,150,150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/omkar/.local/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /Users/omkar/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 16, 150, 150)      448       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 16, 150, 150)      2320      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 16, 75, 75)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 32, 75, 75)        4640      \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 32, 75, 75)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 32, 37, 37)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 64, 37, 37)        18496     \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 64, 37, 37)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 64, 18, 18)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 96, 18, 18)        55392     \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 96, 16, 16)        83040     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 96, 8, 8)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 128, 8, 8)         110720    \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 128, 6, 6)         147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 128, 3, 3)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 1152)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                73792     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 542,738\n",
      "Trainable params: 542,738\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def swish_activation(x):\n",
    "    return (K.sigmoid(x) * x)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(16, (3, 3), activation='relu', padding=\"same\", input_shape=(3,150,150)))\n",
    "model.add(Conv2D(16, (3, 3), padding=\"same\", activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', padding=\"same\", input_shape=(3,150,150)))\n",
    "model.add(Conv2D(32, (3, 3), padding=\"same\", activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), activation='relu', padding=\"same\"))\n",
    "model.add(Conv2D(64, (3, 3), padding=\"same\", activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(96, (3, 3), dilation_rate=(2, 2), activation='relu', padding=\"same\"))\n",
    "model.add(Conv2D(96, (3, 3), padding=\"valid\", activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(128, (3, 3), dilation_rate=(2, 2), activation='relu', padding=\"same\"))\n",
    "model.add(Conv2D(128, (3, 3), padding=\"valid\", activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(64, activation=swish_activation))\n",
    "model.add(Dropout(0.4))\n",
    "\n",
    "\n",
    "model.add(Dense(2 , activation='sigmoid'))\n",
    "\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "                  optimizer=RMSprop(lr=0.00005),\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_40 (Conv2D)           (None, 96, 71, 71)        23424     \n",
      "_________________________________________________________________\n",
      "activation_62 (Activation)   (None, 96, 71, 71)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_24 (MaxPooling (None, 96, 35, 35)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_41 (Conv2D)           (None, 256, 27, 27)       1990912   \n",
      "_________________________________________________________________\n",
      "activation_63 (Activation)   (None, 256, 27, 27)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_25 (MaxPooling (None, 256, 13, 13)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_42 (Conv2D)           (None, 384, 11, 11)       885120    \n",
      "_________________________________________________________________\n",
      "activation_64 (Activation)   (None, 384, 11, 11)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_43 (Conv2D)           (None, 384, 9, 9)         1327488   \n",
      "_________________________________________________________________\n",
      "activation_65 (Activation)   (None, 384, 9, 9)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_44 (Conv2D)           (None, 256, 7, 7)         884992    \n",
      "_________________________________________________________________\n",
      "activation_66 (Activation)   (None, 256, 7, 7)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_26 (MaxPooling (None, 256, 3, 3)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 2304)              0         \n",
      "_________________________________________________________________\n",
      "dense_29 (Dense)             (None, 4096)              9441280   \n",
      "_________________________________________________________________\n",
      "dropout_22 (Dropout)         (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_30 (Dense)             (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "dropout_23 (Dropout)         (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_31 (Dense)             (None, 1000)              4097000   \n",
      "_________________________________________________________________\n",
      "dropout_24 (Dropout)         (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "dense_32 (Dense)             (None, 2)                 2002      \n",
      "=================================================================\n",
      "Total params: 35,433,530\n",
      "Trainable params: 35,433,530\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense , Activation\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Flatten\n",
    "from keras.constraints import maxnorm\n",
    "from keras.optimizers import SGD , RMSprop\n",
    "from keras.layers import Conv2D , BatchNormalization\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.utils import np_utils\n",
    "from keras import backend as K\n",
    "K.set_image_dim_ordering('th')\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "\n",
    "model.add(Conv2D(filters=96, input_shape=(3,150,150), kernel_size=(9,9), strides=(2,2), padding=\"valid\"))\n",
    "model.add(Activation(\"relu\"))\n",
    "# Max Pooling\n",
    "model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2), padding=\"valid\"))\n",
    "\n",
    "\n",
    "model.add(Conv2D(filters=256, kernel_size=(9,9), strides=(1,1), padding=\"valid\"))\n",
    "model.add(Activation(\"relu\"))\n",
    "# Max Pooling\n",
    "model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2), padding=\"valid\"))\n",
    "\n",
    "\n",
    "model.add(Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), padding=\"valid\"))\n",
    "model.add(Activation(\"relu\"))\n",
    "\n",
    "# 4th Convolutional Layer\n",
    "model.add(Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), padding=\"valid\"))\n",
    "model.add(Activation(\"relu\"))\n",
    "\n",
    "# 5th Convolutional Layer\n",
    "model.add(Conv2D(filters=256, kernel_size=(3,3), strides=(1,1), padding=\"valid\"))\n",
    "model.add(Activation(\"relu\"))\n",
    "# Max Pooling\n",
    "model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2), padding=\"valid\"))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "# 1st Fully Connected Layer\n",
    "model.add(Dense(4096 , activation=\"relu\"))\n",
    "\n",
    "# Add Dropout to prevent overfitting\n",
    "model.add(Dropout(0.4))\n",
    "\n",
    "# 2nd Fully Connected Layer\n",
    "model.add(Dense(4096 , activation=\"relu\"))\n",
    "\n",
    "# Add Dropout\n",
    "model.add(Dropout(0.4))\n",
    "\n",
    "# 3rd Fully Connected Layer\n",
    "model.add(Dense(1000,activation=\"relu\"))\n",
    "\n",
    "# Add Dropout\n",
    "model.add(Dropout(0.4))\n",
    "\n",
    "model.add(Dense(2,activation=\"softmax\"))\n",
    "\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "                  optimizer=RMSprop(lr=0.00005),\n",
    "                  metrics=['accuracy'])\n",
    "model.summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 256\n",
    "epochs = 6\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/omkar/.local/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 5216 samples, validate on 624 samples\n",
      "Epoch 1/6\n",
      "5216/5216 [==============================] - 810s 155ms/step - loss: 0.4959 - acc: 0.7897 - val_loss: 0.6818 - val_acc: 0.7019\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.70192, saving model to weights.hdf5\n",
      "Epoch 2/6\n",
      "5216/5216 [==============================] - 879s 168ms/step - loss: 0.2802 - acc: 0.8911 - val_loss: 0.7493 - val_acc: 0.7276\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.70192 to 0.72756, saving model to weights.hdf5\n",
      "Epoch 3/6\n",
      "5216/5216 [==============================] - 841s 161ms/step - loss: 0.2386 - acc: 0.9087 - val_loss: 0.5285 - val_acc: 0.7644\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.72756 to 0.76442, saving model to weights.hdf5\n",
      "Epoch 4/6\n",
      "5216/5216 [==============================] - 773s 148ms/step - loss: 0.2053 - acc: 0.9179 - val_loss: 0.8595 - val_acc: 0.7035\n",
      "\n",
      "Epoch 00004: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-06.\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.76442\n",
      "Epoch 5/6\n",
      "5216/5216 [==============================] - 773s 148ms/step - loss: 0.1318 - acc: 0.9488 - val_loss: 0.7931 - val_acc: 0.7580\n",
      "\n",
      "Epoch 00005: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-07.\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.76442\n",
      "Epoch 6/6\n",
      "5216/5216 [==============================] - 765s 147ms/step - loss: 0.1219 - acc: 0.9551 - val_loss: 0.8205 - val_acc: 0.7580\n",
      "\n",
      "Epoch 00006: ReduceLROnPlateau reducing learning rate to 4.999999987376214e-08.\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.76442\n"
     ]
    }
   ],
   "source": [
    "\n",
    "history = model.fit(X_train, y_train, validation_data = (X_test , y_test) ,callbacks=[lr_reduce,checkpoint] ,\n",
    "          epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "pred = model.predict(X_test)\n",
    "pred = np.argmax(pred,axis = 1) \n",
    "y_true = np.argmax(y_test,axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3.5492392e-06, 9.9999642e-01],\n",
       "       [2.5091898e-02, 9.7490805e-01],\n",
       "       [2.5305671e-03, 9.9746943e-01],\n",
       "       ...,\n",
       "       [3.6205485e-02, 9.6379447e-01],\n",
       "       [1.2806589e-03, 9.9871933e-01],\n",
       "       [1.9707705e-03, 9.9802917e-01]], dtype=float32)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "CM = confusion_matrix(y_true, pred)\n",
    "\n",
    "#fig, ax = plot_confusion_matrix(conf_mat=CM ,  figsize=(5, 5))\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 90, 144],\n",
       "       [  7, 383]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "90.61378205128206"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#recall\n",
    "\n",
    "90/(90+15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_val_data(Dir):\n",
    "    X = []\n",
    "    y =[]\n",
    "    for nextDir in os.listdir(Dir):\n",
    "        if not nextDir.startswith('.'):\n",
    "            if nextDir in ['NORMAL']:\n",
    "                label = 0\n",
    "            elif nextDir in ['PNEUMONIA']:\n",
    "                label = 1\n",
    "            else:\n",
    "                label = 2\n",
    "                \n",
    "            temp = Dir + nextDir\n",
    "                \n",
    "            for file in tqdm(os.listdir(temp)):\n",
    "                img = cv2.imread(temp + '/' + file)\n",
    "                if img is not None:\n",
    "                    img = skimage.transform.resize(img, (150, 150, 3))\n",
    "                    #img_file = scipy.misc.imresize(arr=img_file, size=(150, 150, 3))\n",
    "                    img = np.asarray(img)\n",
    "                    X.append(img)\n",
    "                    y.append(label)\n",
    "                    \n",
    "    X = np.asarray(X)\n",
    "    y = np.asarray(y)\n",
    "    return X,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11/11 [00:00<00:00, 24.43it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 12.58it/s]\n"
     ]
    }
   ],
   "source": [
    "X_val, y_val =get_val_data(VAL_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val=X_val.reshape(17,3,150,150)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = model.predict(X_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_val = np.argmax(prediction,axis = 1) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "CM = confusion_matrix(y_val, prediction_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6, 2],\n",
       "       [0, 9]])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image = cv2.imread('val/NORMAL/NORMAL2-IM-1438-0001.jpeg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image = skimage.transform.resize(test_image, (150, 150, 3))\n",
    "test_image = np.asarray(test_image)\n",
    "test_image=test_image.reshape(1,3,150,150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = model.predict(test_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.6048417 , 0.39515832]], dtype=float32)"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
